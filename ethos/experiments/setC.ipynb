{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IlqliX9gdv8D",
    "outputId": "f98cb9d3-dad6-4e42-b5fe-99adc6278c4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "#####################################################################\n",
    "#                           Set C                                   #\n",
    "#####################################################################\n",
    "# Testing a variety of NN architectures with Embeddings             #\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "pd.set_option('max_colwidth',400)\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, SpatialDropout1D, CuDNNLSTM, Bidirectional, Dense, \\\n",
    "    LSTM, Conv1D, MaxPooling1D, Dropout, concatenate, Flatten, add\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import Input, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential, clone_model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from utilities.preprocess import Preproccesor\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "import time\n",
    "import numpy as np\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "sG8-UNmQAyrE",
    "outputId": "8167e2f0-73a4-4c09-8317-7a9a584d97c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/johnmollas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/johnmollas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9dCSMfw-eUJ6",
    "outputId": "617655d5-5c50-4f04-b5c1-cd086435c528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method     | F1score Precisi Recall  Accurac Specifi Sensiti\n"
     ]
    }
   ],
   "source": [
    "X, y = Preproccesor.load_data(True)\n",
    "class_names = ['noHateSpeech', 'hateSpeech']\n",
    "f = open(\"../results/setC.txt\", \"a+\")\n",
    "f.write(\"{:<10} | {:<7} {:<7} {:<7} {:<7} {:<7} {:<7} \\n\".format('Method','F1score','Precisi','Recall','Accurac','Specifi','Sensiti'))\n",
    "f.write(\"=========================================================================\\n\")\n",
    "f.close()\n",
    "print (\"{:<10} | {:<7} {:<7} {:<7} {:<7} {:<7} {:<7}\".format('Method','F1score','Precisi','Recall','Accurac','Specifi','Sensiti'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "id": "xMD34FnoeN6H",
    "outputId": "b447bcbc-d273-48ed-b88b-6952904b7809",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-07 16:20:22--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 2606:4700:10::6816:4b8e, 2606:4700:10::6816:4a8e, 2606:4700:10::ac43:904, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|2606:4700:10::6816:4b8e|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1523785255 (1,4G) [application/zip]\n",
      "Saving to: ‘crawl-300d-2M.vec.zip’\n",
      "\n",
      "crawl-300d-2M.vec.z 100%[===================>]   1,42G  4,80MB/s    in 5m 34s  \n",
      "\n",
      "2020-11-07 16:25:58 (4,35 MB/s) - ‘crawl-300d-2M.vec.zip’ saved [1523785255/1523785255]\n",
      "\n",
      "--2020-11-07 16:25:58--  http://nlp.stanford.edu/data/glove.42B.300d.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.42B.300d.zip [following]\n",
      "--2020-11-07 16:25:59--  https://nlp.stanford.edu/data/glove.42B.300d.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip [following]\n",
      "--2020-11-07 16:26:00--  http://downloads.cs.stanford.edu/nlp/data/glove.42B.300d.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1877800501 (1,7G) [application/zip]\n",
      "Saving to: ‘glove.42B.300d.zip’\n",
      "\n",
      "glove.42B.300d.zip  100%[===================>]   1,75G  1,32MB/s    in 30m 15s \n",
      "\n",
      "2020-11-07 16:56:15 (1011 KB/s) - ‘glove.42B.300d.zip’ saved [1877800501/1877800501]\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/crawl-300d-2M.vec.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-2b735d89f27d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wget 'http://nlp.stanford.edu/data/glove.42B.300d.zip' \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/crawl-300d-2M.vec.zip\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilelist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/crawl-300d-2M.vec.zip'"
     ]
    }
   ],
   "source": [
    "!wget 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip'\n",
    "!wget 'http://nlp.stanford.edu/data/glove.42B.300d.zip' \n",
    "import zipfile\n",
    "with zipfile.ZipFile(\"/content/crawl-300d-2M.vec.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    print(zip_ref.filelist)\n",
    "with zipfile.ZipFile(\"/content/glove.42B.300d.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "    print(zip_ref.filelist)\n",
    "\n",
    "del zip_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "V3Ub11VQQ6uI"
   },
   "outputs": [],
   "source": [
    "!rm '/content/crawl-300d-2M.vec.zip'\n",
    "!rm '/content/glove.42B.300d.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sJmfoG1SeYuk"
   },
   "outputs": [],
   "source": [
    "def specificity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    if(tn+fp)>0:\n",
    "        speci = tn/(tn+fp)\n",
    "        return speci\n",
    "    return 0\n",
    "def sensitivity(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    if(tp+fn)>0:\n",
    "        sensi = tp/(tp+fn)\n",
    "        return sensi\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "T3cVmRJwe4gE"
   },
   "outputs": [],
   "source": [
    "embedding_path1 = \"/embeddings/crawl-300d-2M.vec\" #FastText\n",
    "embedding_path2 = \"/embeddings/glove.42B.300d.txt\" #Glove 300d\n",
    "embed_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mGSO0Vv1fcN4"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr):\n",
    "    return word, np.asarray(arr, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SM-R5Y-7f10f"
   },
   "outputs": [],
   "source": [
    "def build_matrix(embedding_path, tk, max_features):\n",
    "    embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path, encoding = \"utf-8\"))\n",
    "\n",
    "    word_index = tk.word_index\n",
    "    nb_words = max_features\n",
    "    embedding_matrix = np.zeros((nb_words + 1, 300))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features:\n",
    "            continue\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "def create_embedding_matrix(embed, tk, max_features):\n",
    "    if embed == 1:\n",
    "        return build_matrix(embedding_path1, tk, max_features)\n",
    "    elif embed == 2:\n",
    "        return build_matrix(embedding_path2, tk, max_features)\n",
    "    else:\n",
    "        return np.concatenate([build_matrix(embedding_path1, tk, max_features), build_matrix(embedding_path2, tk, max_features)], axis=-1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "0oEX9FDJg7WE"
   },
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BRIzXMiphJoq"
   },
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                              K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0], self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "IcsGGos6hJ_0"
   },
   "outputs": [],
   "source": [
    "def build_model1(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, embedding_matrix, lr=0.0, lr_d=0.0, spatial_dr=0.0, dense_units=128, conv_size=128, dr=0.2, patience=3, fold_id=1):\n",
    "    file_path = f\"best_model_fold_{fold_id}.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor=\"val_acc\", verbose=1, save_best_only=True, mode=\"max\")\n",
    "    early_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=patience)\n",
    "    inp = Input(shape=(max_len,))\n",
    "    x = Embedding(max_features + 1, embed_size * 2, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
    "    att = Attention(max_len)(x1)\n",
    "    x = Conv1D(conv_size, 2, activation='relu', padding='same')(x1)\n",
    "    x = MaxPooling1D(5, padding='same')(x)\n",
    "    x = Conv1D(conv_size, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling1D(5, padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = concatenate([x, att])\n",
    "    x = Dropout(dr)(Dense(dense_units, activation='relu')(x))\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    model2 = Model(inputs=inp, outputs=x)\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_valid, y_valid), verbose=1, callbacks=[early_stop, check_point])\n",
    "    model2.load_weights(file_path)\n",
    "    model2.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    return model2\n",
    "def build_model2(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, embedding_matrix, lr=0.0, lr_d=0.0, spatial_dr=0.0, dense_units=128, conv_size=128, dr=0.2, patience=3, fold_id=1):\n",
    "    file_path = f\"best_model_fold_{fold_id}.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor=\"val_acc\", verbose=1,save_best_only=True, mode=\"max\")\n",
    "    early_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=patience)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_features + 1, embed_size * 2, input_length=max_len, weights=[embedding_matrix], trainable=False))\n",
    "    model.add(Conv1D(200, 10, activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dropout(rate=0.35))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model2 = model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_valid, y_valid), verbose=1, callbacks=[early_stop, check_point])\n",
    "    model2.load_weights(file_path)\n",
    "    model2.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    return model2\n",
    "def build_model3(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, embedding_matrix, lr=0.0, lr_d=0.0, spatial_dr=0.0, dense_units=128, conv_size=128, dr=0.2, patience=3, fold_id=1):\n",
    "    file_path = f\"best_model_fold_{fold_id}.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor=\"val_acc\", verbose=1,save_best_only=True, mode=\"max\")\n",
    "    early_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=patience)\n",
    "    main_input = Input(shape = (max_len,),name='main_input')\n",
    "    glove_Embed = (Embedding(max_features + 1, embed_size * 2, weights=[embedding_matrix], trainable=False))(main_input)\n",
    "    y = LSTM(300)(glove_Embed)\n",
    "    y = Dense(200, activation='relu')(y)\n",
    "    y = Dropout(rate=0.15)(y)\n",
    "    z = Dense(100, activation='relu')(y)\n",
    "    output_lay = Dense(1, activation='sigmoid')(z)\n",
    "    model = Model(inputs=[main_input], outputs=[output_lay])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    model2 = Model(inputs=[main_input], outputs=[output_lay])\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_valid, y_valid), verbose=1, callbacks=[early_stop, check_point])\n",
    "    model2.load_weights(file_path)\n",
    "    model2.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    return model2\n",
    "def build_model4(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, embedding_matrix, lr=0.0, lr_d=0.0, spatial_dr=0.0, dense_units=128, conv_size=128, dr=0.2, patience=3, fold_id=1):\n",
    "    file_path = f\"best_model_fold_{fold_id}.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor=\"val_acc\", verbose=1,save_best_only=True, mode=\"max\")\n",
    "    early_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=patience)\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    glove_Embed = (Embedding(max_features + 1, embed_size * 2, input_length=max_len, weights=[embedding_matrix], trainable=False))(main_input)\n",
    "\n",
    "    x0 = Conv1D(128, 10, activation='relu')(glove_Embed)\n",
    "    x1 = Conv1D(64, 5, activation='relu')(x0)\n",
    "    x2 = Conv1D(32, 4, activation='relu')(x1)\n",
    "    x3 = Conv1D(16, 3, activation='relu')(x2)\n",
    "    x4 = Conv1D(8, 5, activation='relu')(x3)\n",
    "    x = MaxPooling1D(pool_size=3)(x4)\n",
    "    x = Dropout(rate=0.25)(x)\n",
    "    x = LSTM(100)(x)\n",
    "\n",
    "    p = MaxPooling1D(pool_size=10)(x0)\n",
    "    p = Dropout(rate=0.15)(p)\n",
    "    p = LSTM(100)(p)\n",
    "\n",
    "    o = MaxPooling1D(pool_size=8)(x1)\n",
    "    o = Dropout(rate=0.15)(o)\n",
    "    o = LSTM(100)(o)\n",
    "\n",
    "    i = MaxPooling1D(pool_size=6)(x2)\n",
    "    i = Dropout(rate=0.15)(i)\n",
    "    i = LSTM(100)(i)\n",
    "\n",
    "    r = MaxPooling1D(pool_size=4)(x3)\n",
    "    r = Dropout(rate=0.15)(r)\n",
    "    r = LSTM(100)(r)\n",
    "\n",
    "    t = MaxPooling1D(pool_size=3)(x4)\n",
    "    t = Dropout(rate=0.15)(t)\n",
    "    t = LSTM(100)(t)\n",
    "\n",
    "    y = LSTM(500)(glove_Embed)\n",
    "    y = Dense(250,activation='relu')(y)\n",
    "    y = Dropout(rate=0.15)(y)\n",
    "\n",
    "    z = concatenate([x, p, o, i, r, t, y])\n",
    "\n",
    "    z = Dense(400,activation='relu')(z)\n",
    "    z = Dropout(0.15)(z)\n",
    "    z = Dense(200,activation='relu')(z)\n",
    "    z = Dense(100,activation='relu')(z)\n",
    "    z = Dropout(0.15)(z)\n",
    "    z = Dense(50,activation='relu')(z)\n",
    "    output_lay = Dense(1, activation='sigmoid')(z)\n",
    "    model = Model(inputs=[main_input], outputs=[output_lay])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    model2 = Model(inputs=[main_input], outputs=[output_lay])\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_valid, y_valid), verbose=1, callbacks=[early_stop, check_point])\n",
    "    model2.load_weights(file_path)\n",
    "    model2.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    return model2\n",
    "def build_model5(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, embedding_matrix, lr=0.0, lr_d=0.0, spatial_dr=0.0, dense_units=128, conv_size=128, dr=0.2, patience=3, fold_id=1):\n",
    "    file_path = f\"best_model_fold_{fold_id}.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor=\"val_acc\", verbose=1,save_best_only=True, mode=\"max\")\n",
    "    early_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=patience)\n",
    "    main_input = Input(shape=(max_len,), dtype='int32', name='main_input')\n",
    "    x = (Embedding(max_features + 1, embed_size*2, input_length=max_len, weights=[embedding_matrix], trainable=False))(main_input)\n",
    "    x = SpatialDropout1D(0.3)(x)\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    hidden = concatenate([\n",
    "        GlobalMaxPooling1D()(x),\n",
    "        GlobalAveragePooling1D()(x),\n",
    "    ])\n",
    "    hidden = Dense(1024, activation='relu')(hidden)\n",
    "    hidden = Dense(512, activation='relu')(hidden)\n",
    "    output_lay = Dense(1, activation='sigmoid')(hidden)\n",
    "    model = Model(inputs=[main_input], outputs=[output_lay])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    model2 = Model(inputs=[main_input], outputs=[output_lay])\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_valid, y_valid), verbose=1, callbacks=[early_stop, check_point])\n",
    "    model2.load_weights(file_path)\n",
    "    model2.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    return model2\n",
    "def build_model6(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, embedding_matrix, lr=0.0, lr_d=0.0, spatial_dr=0.0, dense_units=128, conv_size=128, dr=0.2, patience=3, fold_id=1):\n",
    "    file_path = f\"best_model_fold_{fold_id}.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor=\"val_acc\", verbose=1,save_best_only=True, mode=\"max\")\n",
    "    early_stop = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=patience)\n",
    "    main_input = Input(shape=(max_len,), name='main_input')\n",
    "    x = (Embedding(max_features + 1, embed_size*2, input_length=max_len, weights=[embedding_matrix], trainable=False))(main_input)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    x = Bidirectional(CuDNNLSTM(128, return_sequences=True))(x)\n",
    "    hidden = concatenate([\n",
    "        Attention(max_len)(x),\n",
    "        GlobalMaxPooling1D()(x),\n",
    "    ])\n",
    "    hidden = Dense(1024, activation='relu')(hidden)\n",
    "    hidden = Dense(512, activation='relu')(hidden)\n",
    "    output_lay = Dense(1, activation='sigmoid')(hidden)\n",
    "    model = Model(inputs=[main_input], outputs=[output_lay])\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    model2 = Model(inputs=[main_input], outputs=[output_lay])\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_valid, y_valid), verbose=1, callbacks=[early_stop, check_point])\n",
    "    model2.load_weights(file_path)\n",
    "    model2.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=[\"accuracy\"])\n",
    "    return model2\n",
    "def run_model_on_fold(name, max_len, embed_size, embed, bulid_fun):\n",
    "    max_features = 50000\n",
    "    scores = {}\n",
    "    scores.setdefault('fit_time', [])\n",
    "    scores.setdefault('score_time', [])\n",
    "    scores.setdefault('test_F1', [])\n",
    "    scores.setdefault('test_Precision', [])\n",
    "    scores.setdefault('test_Recall', [])\n",
    "    scores.setdefault('test_Accuracy', [])\n",
    "    scores.setdefault('test_Specificity', [])\n",
    "    scores.setdefault('test_Sensitivity', [])\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X[train_index], X[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        tk = Tokenizer(lower = True, filters='', num_words=max_features, oov_token = True)\n",
    "        tk.fit_on_texts(X_train)\n",
    "        train_tokenized = tk.texts_to_sequences(X_train)\n",
    "        valid_tokenized = tk.texts_to_sequences(X_valid)\n",
    "        X_train = pad_sequences(train_tokenized, maxlen=max_len)\n",
    "        X_valid = pad_sequences(valid_tokenized, maxlen=max_len)\n",
    "        embedding_matrix = create_embedding_matrix(embed, tk, max_features)\n",
    "        \n",
    "        model = bulid_fun(X_train, y_train, X_valid, y_valid, max_len, max_features, embed_size, embedding_matrix,\n",
    "                             lr=1e-3, lr_d=0, spatial_dr=0.1, dense_units=128, conv_size=128, dr=0.1, patience=4,\n",
    "                             fold_id=fold_n)\n",
    "\n",
    "        y_preds = []\n",
    "        for i in model.predict(X_valid):\n",
    "            if i[0] >= 0.5:\n",
    "                y_preds.append(1)\n",
    "            else:\n",
    "                y_preds.append(0)\n",
    "        print(accuracy_score(y_valid, y_preds))\n",
    "        scores['test_F1'].append(f1_score(y_valid, y_preds, average='macro'))\n",
    "        scores['test_Precision'].append(precision_score(y_valid, y_preds, average='macro'))\n",
    "        scores['test_Recall'].append(recall_score(y_valid, y_preds, average='macro'))\n",
    "        scores['test_Accuracy'].append(accuracy_score(y_valid, y_preds))\n",
    "        scores['test_Specificity'].append(specificity(y_valid, y_preds))\n",
    "        scores['test_Sensitivity'].append(sensitivity(y_valid, y_preds))\n",
    "    f = open(\"../results/setC.txt\", \"a+\")\n",
    "    f.write(\"{:<10} | {:<7} {:<7} {:<7} {:<7} {:<7} {:<7}\".format(str(name)[:7],\n",
    "                                                               str('%.4f' % (sum(scores['test_F1']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Precision']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Recall']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Accuracy']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Specificity']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Sensitivity']) / 10)))+'\\n')\n",
    "    f.close()\n",
    "    print(\"{:<10} | {:<7} {:<7} {:<7} {:<7} {:<7} {:<7}\".format(str(name)[:7],\n",
    "                                                               str('%.4f' % (sum(scores['test_F1']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Precision']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Recall']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Accuracy']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Specificity']) / 10)),\n",
    "                                                               str('%.4f' % (sum(scores['test_Sensitivity']) / 10))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kw59OxJjATrs",
    "outputId": "9fad3096-4b2e-41df-e885-c36027e53ac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Wed Aug 28 05:19:53 2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0828 05:25:08.278795 139950453757824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0828 05:25:08.365013 139950453757824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0828 05:25:08.368760 139950453757824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0828 05:25:08.384673 139950453757824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0828 05:25:08.385567 139950453757824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0828 05:25:12.486285 139950453757824 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0828 05:25:14.688489 139950453757824 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0828 05:25:14.697924 139950453757824 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.6689 - acc: 0.6243 - val_loss: 0.6382 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71287, saving model to best_model_fold_0.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.5799 - acc: 0.7179 - val_loss: 0.5651 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.71287\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.5068 - acc: 0.7804 - val_loss: 0.5322 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.71287 to 0.73267, saving model to best_model_fold_0.hdf5\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.4099 - acc: 0.8272 - val_loss: 0.6406 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73267\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.3412 - acc: 0.8551 - val_loss: 0.6439 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73267\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.2437 - acc: 0.9019 - val_loss: 0.5834 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73267\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.1821 - acc: 0.9242 - val_loss: 0.7037 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.73267 to 0.74257, saving model to best_model_fold_0.hdf5\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.1654 - acc: 0.9487 - val_loss: 0.6670 - val_acc: 0.7822\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.74257 to 0.78218, saving model to best_model_fold_0.hdf5\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.1090 - acc: 0.9621 - val_loss: 0.7732 - val_acc: 0.7624\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78218\n",
      "Epoch 10/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.1353 - acc: 0.9487 - val_loss: 0.8004 - val_acc: 0.7921\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.78218 to 0.79208, saving model to best_model_fold_0.hdf5\n",
      "0.7920792079207921\n",
      "Fold 1 started at Wed Aug 28 05:26:30 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.6726 - acc: 0.5864 - val_loss: 0.6343 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63366, saving model to best_model_fold_1.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.5619 - acc: 0.7101 - val_loss: 0.6434 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63366 to 0.70297, saving model to best_model_fold_1.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.4683 - acc: 0.7804 - val_loss: 0.6200 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.70297 to 0.70297, saving model to best_model_fold_1.hdf5\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.3885 - acc: 0.8216 - val_loss: 0.7025 - val_acc: 0.7228\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70297 to 0.72277, saving model to best_model_fold_1.hdf5\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.3539 - acc: 0.8495 - val_loss: 0.7573 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.72277\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.2375 - acc: 0.9064 - val_loss: 0.9003 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72277\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.1893 - acc: 0.9197 - val_loss: 0.9383 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72277\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.1208 - acc: 0.9543 - val_loss: 1.7679 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.72277\n",
      "0.7227722772277227\n",
      "Fold 2 started at Wed Aug 28 05:32:51 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.6624 - acc: 0.6031 - val_loss: 0.6672 - val_acc: 0.5941\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59406, saving model to best_model_fold_2.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.5903 - acc: 0.7124 - val_loss: 0.6007 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59406 to 0.66337, saving model to best_model_fold_2.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.4905 - acc: 0.7804 - val_loss: 0.7552 - val_acc: 0.5941\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.66337\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.4114 - acc: 0.8183 - val_loss: 0.5802 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66337 to 0.74257, saving model to best_model_fold_2.hdf5\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.3669 - acc: 0.8384 - val_loss: 0.6357 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.74257\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.2450 - acc: 0.8874 - val_loss: 0.8141 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.74257\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.1981 - acc: 0.9153 - val_loss: 0.8138 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.74257\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 7s 8ms/step - loss: 0.1276 - acc: 0.9431 - val_loss: 0.9175 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74257\n",
      "0.7425742574257426\n",
      "Fold 3 started at Wed Aug 28 05:39:07 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 9s 10ms/step - loss: 0.6726 - acc: 0.6102 - val_loss: 0.5917 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.5471 - acc: 0.7450 - val_loss: 0.7623 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.67000\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.5223 - acc: 0.7528 - val_loss: 0.5289 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.67000 to 0.74000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.4285 - acc: 0.8140 - val_loss: 0.6597 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.74000\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.3840 - acc: 0.8441 - val_loss: 0.5595 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.74000 to 0.75000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.3079 - acc: 0.8797 - val_loss: 0.5063 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.75000 to 0.77000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.2019 - acc: 0.9243 - val_loss: 0.7979 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77000\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.1919 - acc: 0.9187 - val_loss: 0.6824 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77000\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.1140 - acc: 0.9532 - val_loss: 0.9681 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.77000\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.0979 - acc: 0.9666 - val_loss: 0.7823 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.77000\n",
      "0.77\n",
      "Fold 4 started at Wed Aug 28 05:45:37 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 10s 11ms/step - loss: 0.6788 - acc: 0.5523 - val_loss: 0.6742 - val_acc: 0.5700\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.57000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.5914 - acc: 0.6882 - val_loss: 0.5864 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.57000 to 0.64000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.4949 - acc: 0.7606 - val_loss: 0.4887 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.64000 to 0.72000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.3932 - acc: 0.8163 - val_loss: 0.5951 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.72000\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.3624 - acc: 0.8341 - val_loss: 0.5130 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72000 to 0.77000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.2632 - acc: 0.8864 - val_loss: 0.5375 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77000\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.2200 - acc: 0.9165 - val_loss: 0.6252 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77000\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.1281 - acc: 0.9432 - val_loss: 0.8122 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77000\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 7s 8ms/step - loss: 0.1117 - acc: 0.9644 - val_loss: 1.0008 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.77000\n",
      "0.77\n",
      "Fold 5 started at Wed Aug 28 05:52:07 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.6653 - acc: 0.5962 - val_loss: 0.6304 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66667, saving model to best_model_fold_5.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.5562 - acc: 0.7319 - val_loss: 0.5936 - val_acc: 0.6465\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.66667\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.4971 - acc: 0.7853 - val_loss: 0.6208 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.66667\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.3946 - acc: 0.8309 - val_loss: 0.5941 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66667 to 0.71717, saving model to best_model_fold_5.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.3233 - acc: 0.8699 - val_loss: 0.5798 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71717 to 0.72727, saving model to best_model_fold_5.hdf5\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.2371 - acc: 0.9088 - val_loss: 0.6009 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.72727 to 0.74747, saving model to best_model_fold_5.hdf5\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1809 - acc: 0.9266 - val_loss: 0.9160 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.74747\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1126 - acc: 0.9611 - val_loss: 0.9310 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74747\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1032 - acc: 0.9600 - val_loss: 1.4164 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.74747\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1182 - acc: 0.9555 - val_loss: 1.2528 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.74747\n",
      "0.7474747474747475\n",
      "Fold 6 started at Wed Aug 28 05:58:38 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.6758 - acc: 0.5795 - val_loss: 0.6052 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67677, saving model to best_model_fold_6.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.5512 - acc: 0.7341 - val_loss: 0.6156 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.67677 to 0.73737, saving model to best_model_fold_6.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.4690 - acc: 0.7909 - val_loss: 0.6099 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.73737\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.3696 - acc: 0.8454 - val_loss: 0.6413 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73737\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.2926 - acc: 0.8821 - val_loss: 0.7024 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73737\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.2554 - acc: 0.8954 - val_loss: 0.6850 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73737\n",
      "0.7373737373737373\n",
      "Fold 7 started at Wed Aug 28 06:04:46 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 10s 12ms/step - loss: 0.6832 - acc: 0.5873 - val_loss: 0.6022 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67677, saving model to best_model_fold_7.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.5790 - acc: 0.7164 - val_loss: 0.5519 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.67677 to 0.71717, saving model to best_model_fold_7.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.5116 - acc: 0.7686 - val_loss: 0.4859 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.71717 to 0.77778, saving model to best_model_fold_7.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.4191 - acc: 0.8220 - val_loss: 0.5597 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77778\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.3603 - acc: 0.8476 - val_loss: 0.5230 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77778\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.2443 - acc: 0.8932 - val_loss: 0.6077 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77778\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1704 - acc: 0.9321 - val_loss: 0.6701 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77778\n",
      "0.7777777777777778\n",
      "Fold 8 started at Wed Aug 28 06:11:00 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.6851 - acc: 0.5862 - val_loss: 0.5980 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69697, saving model to best_model_fold_8.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.5601 - acc: 0.7297 - val_loss: 0.5510 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69697 to 0.75758, saving model to best_model_fold_8.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.5158 - acc: 0.7597 - val_loss: 0.4944 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.75758 to 0.76768, saving model to best_model_fold_8.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.3975 - acc: 0.8331 - val_loss: 0.5980 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.76768\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.3472 - acc: 0.8476 - val_loss: 0.5035 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.76768\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.2546 - acc: 0.8943 - val_loss: 0.4948 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.76768 to 0.81818, saving model to best_model_fold_8.hdf5\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.2026 - acc: 0.9232 - val_loss: 0.6315 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.81818\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1167 - acc: 0.9566 - val_loss: 0.8124 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.81818\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1756 - acc: 0.9210 - val_loss: 0.7677 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.81818\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.0675 - acc: 0.9778 - val_loss: 0.8400 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81818\n",
      "0.8181818181818182\n",
      "Fold 9 started at Wed Aug 28 06:17:35 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.6741 - acc: 0.5895 - val_loss: 0.6202 - val_acc: 0.6465\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64646, saving model to best_model_fold_9.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.5603 - acc: 0.7041 - val_loss: 0.6357 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.64646 to 0.70707, saving model to best_model_fold_9.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.5250 - acc: 0.7442 - val_loss: 0.5424 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.70707\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.4180 - acc: 0.7998 - val_loss: 0.5151 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.70707 to 0.72727, saving model to best_model_fold_9.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.3264 - acc: 0.8509 - val_loss: 0.6642 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72727 to 0.76768, saving model to best_model_fold_9.hdf5\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.2892 - acc: 0.8776 - val_loss: 0.5398 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.76768\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.2040 - acc: 0.9099 - val_loss: 0.7885 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.76768\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1774 - acc: 0.9288 - val_loss: 1.0521 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76768\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 7s 8ms/step - loss: 0.1284 - acc: 0.9511 - val_loss: 0.6389 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.76768\n",
      "0.7676767676767676\n",
      "b6_3_10    | 0.7598  0.7647  0.7612  0.7646  0.7880  0.7343 \n",
      "Fold 0 started at Wed Aug 28 06:24:09 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.6682 - acc: 0.6198 - val_loss: 0.6467 - val_acc: 0.5842\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58416, saving model to best_model_fold_0.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 9s 11ms/step - loss: 0.5900 - acc: 0.7191 - val_loss: 0.6645 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.58416 to 0.63366, saving model to best_model_fold_0.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.4881 - acc: 0.7748 - val_loss: 0.6139 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.63366 to 0.70297, saving model to best_model_fold_0.hdf5\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.4389 - acc: 0.8038 - val_loss: 0.7779 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.70297\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.3471 - acc: 0.8517 - val_loss: 0.6796 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.70297\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.2557 - acc: 0.8907 - val_loss: 0.6957 - val_acc: 0.7624\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.70297 to 0.76238, saving model to best_model_fold_0.hdf5\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.1941 - acc: 0.9309 - val_loss: 0.6558 - val_acc: 0.7624\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.76238\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.1270 - acc: 0.9487 - val_loss: 0.8475 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76238\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.0911 - acc: 0.9688 - val_loss: 0.9417 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.76238\n",
      "Epoch 10/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.0850 - acc: 0.9699 - val_loss: 1.0093 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.76238\n",
      "0.7623762376237624\n",
      "Fold 1 started at Wed Aug 28 06:31:16 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 15s 17ms/step - loss: 0.6621 - acc: 0.6210 - val_loss: 0.6270 - val_acc: 0.6535\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.65347, saving model to best_model_fold_1.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 10s 11ms/step - loss: 0.5327 - acc: 0.7458 - val_loss: 0.9164 - val_acc: 0.6535\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.65347\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 9s 11ms/step - loss: 0.4891 - acc: 0.7659 - val_loss: 0.6690 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.65347 to 0.70297, saving model to best_model_fold_1.hdf5\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.3840 - acc: 0.8294 - val_loss: 0.6403 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.70297\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.4498 - acc: 0.7938 - val_loss: 0.5989 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.70297 to 0.71287, saving model to best_model_fold_1.hdf5\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.2740 - acc: 0.8941 - val_loss: 0.8714 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71287\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.1927 - acc: 0.9376 - val_loss: 0.9617 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71287\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.1681 - acc: 0.9431 - val_loss: 1.0346 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71287\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.1266 - acc: 0.9476 - val_loss: 1.3340 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.71287\n",
      "0.7128712871287128\n",
      "Fold 2 started at Wed Aug 28 06:38:13 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 15s 17ms/step - loss: 0.6728 - acc: 0.5931 - val_loss: 0.6350 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63366, saving model to best_model_fold_2.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 10s 11ms/step - loss: 0.5930 - acc: 0.6934 - val_loss: 0.5883 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63366 to 0.68317, saving model to best_model_fold_2.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 10s 11ms/step - loss: 0.4824 - acc: 0.7770 - val_loss: 0.5560 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.68317 to 0.69307, saving model to best_model_fold_2.hdf5\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 10s 11ms/step - loss: 0.4569 - acc: 0.7960 - val_loss: 0.5705 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69307\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 10s 11ms/step - loss: 0.4090 - acc: 0.8239 - val_loss: 0.5450 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.69307 to 0.71287, saving model to best_model_fold_2.hdf5\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 10s 11ms/step - loss: 0.2901 - acc: 0.8829 - val_loss: 0.6933 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71287\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.2092 - acc: 0.9231 - val_loss: 1.0641 - val_acc: 0.6436\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71287\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.1896 - acc: 0.9153 - val_loss: 0.7391 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71287\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.1161 - acc: 0.9576 - val_loss: 1.1090 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.71287 to 0.71287, saving model to best_model_fold_2.hdf5\n",
      "Epoch 10/10\n",
      "897/897 [==============================] - 9s 10ms/step - loss: 0.0976 - acc: 0.9554 - val_loss: 1.0566 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.71287\n",
      "0.7128712871287128\n",
      "Fold 3 started at Wed Aug 28 06:45:25 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 0.6812 - acc: 0.5601 - val_loss: 0.6279 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 10s 11ms/step - loss: 0.5945 - acc: 0.6993 - val_loss: 0.5687 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63000 to 0.71000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 10s 11ms/step - loss: 0.5035 - acc: 0.7606 - val_loss: 0.5465 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.71000 to 0.73000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 10s 11ms/step - loss: 0.4362 - acc: 0.8051 - val_loss: 0.5303 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73000\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 9s 11ms/step - loss: 0.3549 - acc: 0.8430 - val_loss: 0.6128 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73000\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 9s 11ms/step - loss: 0.2765 - acc: 0.8831 - val_loss: 0.5405 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73000 to 0.76000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 9s 11ms/step - loss: 0.1914 - acc: 0.9287 - val_loss: 0.8549 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.76000\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 9s 10ms/step - loss: 0.1487 - acc: 0.9421 - val_loss: 0.8841 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76000\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 9s 10ms/step - loss: 0.0938 - acc: 0.9644 - val_loss: 0.8697 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.76000\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 9s 10ms/step - loss: 0.0861 - acc: 0.9655 - val_loss: 0.9155 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.76000\n",
      "0.76\n",
      "Fold 4 started at Wed Aug 28 06:52:39 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 0.6627 - acc: 0.5947 - val_loss: 0.6296 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 10s 11ms/step - loss: 0.5348 - acc: 0.7294 - val_loss: 0.5806 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.70000\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 10s 11ms/step - loss: 0.5036 - acc: 0.7606 - val_loss: 0.5169 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.70000 to 0.77000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 9s 10ms/step - loss: 0.3781 - acc: 0.8374 - val_loss: 0.5284 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77000\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 9s 10ms/step - loss: 0.3503 - acc: 0.8463 - val_loss: 0.5733 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77000\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 9s 10ms/step - loss: 0.2501 - acc: 0.9009 - val_loss: 0.7195 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77000\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 9s 10ms/step - loss: 0.1769 - acc: 0.9220 - val_loss: 0.6443 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77000\n",
      "0.77\n",
      "Fold 5 started at Wed Aug 28 06:59:25 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 17s 19ms/step - loss: 0.6755 - acc: 0.5862 - val_loss: 0.6230 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.65657, saving model to best_model_fold_5.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.5684 - acc: 0.7319 - val_loss: 0.6827 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.65657\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4505 - acc: 0.8031 - val_loss: 0.6276 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.65657 to 0.66667, saving model to best_model_fold_5.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3919 - acc: 0.8276 - val_loss: 0.6132 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66667 to 0.70707, saving model to best_model_fold_5.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3208 - acc: 0.8665 - val_loss: 0.7288 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.70707\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2424 - acc: 0.8977 - val_loss: 0.7981 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.70707\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1737 - acc: 0.9288 - val_loss: 0.9751 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.70707\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1586 - acc: 0.9321 - val_loss: 0.7911 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.70707 to 0.73737, saving model to best_model_fold_5.hdf5\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1311 - acc: 0.9477 - val_loss: 1.0523 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.73737\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0880 - acc: 0.9644 - val_loss: 1.0312 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.73737\n",
      "0.7373737373737373\n",
      "Fold 6 started at Wed Aug 28 07:06:47 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 18s 20ms/step - loss: 0.6353 - acc: 0.6062 - val_loss: 0.6445 - val_acc: 0.5758\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.57576, saving model to best_model_fold_6.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.5701 - acc: 0.7253 - val_loss: 0.5944 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.57576 to 0.72727, saving model to best_model_fold_6.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4628 - acc: 0.7853 - val_loss: 0.5728 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.72727 to 0.75758, saving model to best_model_fold_6.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3940 - acc: 0.8142 - val_loss: 0.8877 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75758\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3306 - acc: 0.8632 - val_loss: 0.7810 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75758\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2497 - acc: 0.8899 - val_loss: 0.7504 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75758\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1927 - acc: 0.9277 - val_loss: 1.1556 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.75758 to 0.78788, saving model to best_model_fold_6.hdf5\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1363 - acc: 0.9444 - val_loss: 1.0126 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.78788\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1034 - acc: 0.9566 - val_loss: 1.1889 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78788\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1036 - acc: 0.9611 - val_loss: 1.1769 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78788\n",
      "0.7878787878787878\n",
      "Fold 7 started at Wed Aug 28 07:14:09 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 18s 20ms/step - loss: 0.6868 - acc: 0.5617 - val_loss: 0.5791 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72727, saving model to best_model_fold_7.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.5922 - acc: 0.6863 - val_loss: 0.6014 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.72727 to 0.77778, saving model to best_model_fold_7.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.5017 - acc: 0.7764 - val_loss: 0.5864 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.77778\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4071 - acc: 0.8298 - val_loss: 0.5137 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77778\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3359 - acc: 0.8509 - val_loss: 0.5594 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77778\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2731 - acc: 0.8788 - val_loss: 0.6909 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77778\n",
      "0.7777777777777778\n",
      "Fold 8 started at Wed Aug 28 07:20:57 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 19s 21ms/step - loss: 0.6710 - acc: 0.6229 - val_loss: 0.6227 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69697, saving model to best_model_fold_8.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.5914 - acc: 0.6986 - val_loss: 0.5293 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69697 to 0.70707, saving model to best_model_fold_8.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4971 - acc: 0.7586 - val_loss: 0.4899 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.70707 to 0.72727, saving model to best_model_fold_8.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4205 - acc: 0.8176 - val_loss: 0.4767 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.72727 to 0.77778, saving model to best_model_fold_8.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3308 - acc: 0.8676 - val_loss: 0.5578 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77778\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2726 - acc: 0.8943 - val_loss: 0.6032 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77778\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1935 - acc: 0.9244 - val_loss: 0.9012 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77778\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1531 - acc: 0.9466 - val_loss: 0.7399 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77778\n",
      "0.7777777777777778\n",
      "Fold 9 started at Wed Aug 28 07:28:08 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 19s 21ms/step - loss: 0.6707 - acc: 0.5951 - val_loss: 0.5740 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70707, saving model to best_model_fold_9.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.5775 - acc: 0.7152 - val_loss: 0.5654 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.70707 to 0.71717, saving model to best_model_fold_9.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4867 - acc: 0.7720 - val_loss: 0.5438 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.71717 to 0.72727, saving model to best_model_fold_9.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.4022 - acc: 0.8209 - val_loss: 0.5946 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.72727 to 0.74747, saving model to best_model_fold_9.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.3170 - acc: 0.8676 - val_loss: 0.7094 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.74747\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.2517 - acc: 0.9021 - val_loss: 0.5400 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.74747 to 0.75758, saving model to best_model_fold_9.hdf5\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1972 - acc: 0.9188 - val_loss: 0.4806 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75758\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1298 - acc: 0.9488 - val_loss: 0.8818 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.75758 to 0.78788, saving model to best_model_fold_9.hdf5\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.1137 - acc: 0.9566 - val_loss: 0.7523 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78788\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 10s 11ms/step - loss: 0.0949 - acc: 0.9677 - val_loss: 0.6481 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78788\n",
      "0.7878787878787878\n",
      "b6_3_15    | 0.7536  0.7597  0.7563  0.7587  0.7755  0.7372 \n",
      "Fold 0 started at Wed Aug 28 07:35:40 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 21s 23ms/step - loss: 0.6529 - acc: 0.6154 - val_loss: 0.8811 - val_acc: 0.6238\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.62376, saving model to best_model_fold_0.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.5667 - acc: 0.7179 - val_loss: 0.6778 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.62376 to 0.66337, saving model to best_model_fold_0.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.5535 - acc: 0.7402 - val_loss: 0.5366 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.66337 to 0.68317, saving model to best_model_fold_0.hdf5\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.4808 - acc: 0.7581 - val_loss: 0.5579 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.68317 to 0.75248, saving model to best_model_fold_0.hdf5\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.3883 - acc: 0.8205 - val_loss: 0.5518 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75248\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.3402 - acc: 0.8595 - val_loss: 0.5611 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75248\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.2405 - acc: 0.9075 - val_loss: 0.6544 - val_acc: 0.7228\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75248\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.2135 - acc: 0.9186 - val_loss: 0.7972 - val_acc: 0.7228\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75248\n",
      "0.7524752475247525\n",
      "Fold 1 started at Wed Aug 28 07:43:07 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 22s 24ms/step - loss: 0.6564 - acc: 0.6065 - val_loss: 0.6895 - val_acc: 0.6040\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60396, saving model to best_model_fold_1.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 12s 13ms/step - loss: 0.5746 - acc: 0.7113 - val_loss: 0.6327 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.60396 to 0.71287, saving model to best_model_fold_1.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 11s 13ms/step - loss: 0.4795 - acc: 0.7949 - val_loss: 0.6233 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.71287\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 11s 13ms/step - loss: 0.3941 - acc: 0.8317 - val_loss: 0.6928 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.71287 to 0.71287, saving model to best_model_fold_1.hdf5\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 11s 13ms/step - loss: 0.3439 - acc: 0.8673 - val_loss: 0.9273 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.71287\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.2741 - acc: 0.8930 - val_loss: 0.9506 - val_acc: 0.6436\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71287\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.1601 - acc: 0.9398 - val_loss: 1.3492 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71287\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.1772 - acc: 0.9287 - val_loss: 0.7961 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71287\n",
      "0.7128712871287128\n",
      "Fold 2 started at Wed Aug 28 07:50:32 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 21s 24ms/step - loss: 0.6647 - acc: 0.6187 - val_loss: 0.6515 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68317, saving model to best_model_fold_2.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 12s 13ms/step - loss: 0.5668 - acc: 0.7347 - val_loss: 0.5966 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.68317\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 11s 13ms/step - loss: 0.5200 - acc: 0.7525 - val_loss: 0.5508 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.68317\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.4313 - acc: 0.8004 - val_loss: 0.5218 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.68317 to 0.74257, saving model to best_model_fold_2.hdf5\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.3900 - acc: 0.8428 - val_loss: 0.5749 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.74257\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.2775 - acc: 0.8829 - val_loss: 0.6846 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.74257 to 0.75248, saving model to best_model_fold_2.hdf5\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.2315 - acc: 0.9064 - val_loss: 0.6661 - val_acc: 0.6436\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75248\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.1432 - acc: 0.9409 - val_loss: 0.7914 - val_acc: 0.6535\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75248\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.1153 - acc: 0.9554 - val_loss: 0.9535 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.75248\n",
      "Epoch 10/10\n",
      "897/897 [==============================] - 11s 12ms/step - loss: 0.0774 - acc: 0.9699 - val_loss: 1.1085 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.75248\n",
      "0.7524752475247525\n",
      "Fold 3 started at Wed Aug 28 07:58:25 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 23s 25ms/step - loss: 0.6602 - acc: 0.6258 - val_loss: 0.5974 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 12s 13ms/step - loss: 0.5806 - acc: 0.7016 - val_loss: 0.5251 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69000 to 0.77000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 11s 13ms/step - loss: 0.4979 - acc: 0.7817 - val_loss: 0.5117 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.77000\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 11s 12ms/step - loss: 0.4274 - acc: 0.8129 - val_loss: 0.5789 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77000\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 11s 12ms/step - loss: 0.3556 - acc: 0.8486 - val_loss: 0.6424 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77000\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 11s 13ms/step - loss: 0.2917 - acc: 0.8797 - val_loss: 0.5112 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77000\n",
      "0.77\n",
      "Fold 4 started at Wed Aug 28 08:05:35 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 22s 24ms/step - loss: 0.6692 - acc: 0.5980 - val_loss: 0.6483 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 12s 13ms/step - loss: 0.5713 - acc: 0.7238 - val_loss: 0.6069 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.68000 to 0.76000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 11s 12ms/step - loss: 0.5075 - acc: 0.7695 - val_loss: 0.5435 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.76000\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 11s 13ms/step - loss: 0.4102 - acc: 0.8151 - val_loss: 0.5914 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.76000\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 11s 13ms/step - loss: 0.3438 - acc: 0.8619 - val_loss: 0.5204 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.76000\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 11s 12ms/step - loss: 0.2392 - acc: 0.9042 - val_loss: 0.6106 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.76000\n",
      "0.76\n",
      "Fold 5 started at Wed Aug 28 08:12:45 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 24s 27ms/step - loss: 0.6822 - acc: 0.5806 - val_loss: 0.6752 - val_acc: 0.6465\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64646, saving model to best_model_fold_5.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5661 - acc: 0.7197 - val_loss: 0.5919 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.64646 to 0.69697, saving model to best_model_fold_5.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.4924 - acc: 0.7842 - val_loss: 0.6439 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.69697\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.4235 - acc: 0.8432 - val_loss: 0.7392 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69697\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.3793 - acc: 0.8365 - val_loss: 0.7645 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.69697\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.2974 - acc: 0.8732 - val_loss: 0.6620 - val_acc: 0.6465\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.69697\n",
      "0.696969696969697\n",
      "Fold 6 started at Wed Aug 28 08:20:00 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 24s 27ms/step - loss: 0.6780 - acc: 0.5751 - val_loss: 0.6434 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.73737, saving model to best_model_fold_6.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5513 - acc: 0.7241 - val_loss: 0.5994 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.73737 to 0.75758, saving model to best_model_fold_6.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.4682 - acc: 0.7920 - val_loss: 0.6572 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75758\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3652 - acc: 0.8476 - val_loss: 0.6319 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75758\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3068 - acc: 0.8710 - val_loss: 0.8517 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75758\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2624 - acc: 0.8899 - val_loss: 0.9475 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75758\n",
      "0.7575757575757576\n",
      "Fold 7 started at Wed Aug 28 08:27:18 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 23s 26ms/step - loss: 0.6632 - acc: 0.6129 - val_loss: 0.6301 - val_acc: 0.6061\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60606, saving model to best_model_fold_7.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5569 - acc: 0.7097 - val_loss: 0.5367 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.60606 to 0.75758, saving model to best_model_fold_7.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.4943 - acc: 0.7686 - val_loss: 0.5170 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75758\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.4329 - acc: 0.7987 - val_loss: 0.4343 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.75758 to 0.79798, saving model to best_model_fold_7.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3289 - acc: 0.8465 - val_loss: 0.5581 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79798\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3129 - acc: 0.8610 - val_loss: 0.4878 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79798\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2199 - acc: 0.9043 - val_loss: 0.5564 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79798\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1366 - acc: 0.9477 - val_loss: 0.6397 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79798\n",
      "0.797979797979798\n",
      "Fold 8 started at Wed Aug 28 08:34:56 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 25s 27ms/step - loss: 0.6742 - acc: 0.5818 - val_loss: 0.5825 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.67677, saving model to best_model_fold_8.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5715 - acc: 0.7186 - val_loss: 0.5393 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.67677 to 0.71717, saving model to best_model_fold_8.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.4996 - acc: 0.7508 - val_loss: 0.4793 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.71717 to 0.78788, saving model to best_model_fold_8.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.4143 - acc: 0.8176 - val_loss: 0.5188 - val_acc: 0.8081\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.78788 to 0.80808, saving model to best_model_fold_8.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.3320 - acc: 0.8598 - val_loss: 0.5349 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.80808\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.2540 - acc: 0.8921 - val_loss: 0.5646 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.80808\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.1978 - acc: 0.9188 - val_loss: 0.5933 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.80808\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 11s 13ms/step - loss: 0.1248 - acc: 0.9566 - val_loss: 0.6912 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80808\n",
      "0.8080808080808081\n",
      "Fold 9 started at Wed Aug 28 08:42:39 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 25s 28ms/step - loss: 0.6570 - acc: 0.6207 - val_loss: 0.6449 - val_acc: 0.6061\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60606, saving model to best_model_fold_9.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.5444 - acc: 0.7353 - val_loss: 0.5638 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.60606 to 0.68687, saving model to best_model_fold_9.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.4583 - acc: 0.7909 - val_loss: 0.5887 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.68687\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.4272 - acc: 0.8198 - val_loss: 0.4922 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.68687 to 0.75758, saving model to best_model_fold_9.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.3325 - acc: 0.8521 - val_loss: 0.5568 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75758\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2460 - acc: 0.9021 - val_loss: 0.5936 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75758\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.2215 - acc: 0.9032 - val_loss: 0.5406 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.75758 to 0.77778, saving model to best_model_fold_9.hdf5\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1912 - acc: 0.9310 - val_loss: 0.6797 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77778\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.1276 - acc: 0.9488 - val_loss: 0.8463 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.77778\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 11s 12ms/step - loss: 0.0836 - acc: 0.9677 - val_loss: 0.9000 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.77778\n",
      "0.7777777777777778\n",
      "b6_3_20    | 0.7529  0.7680  0.7582  0.7586  0.7609  0.7554 \n",
      "Fold 0 started at Wed Aug 28 08:50:47 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 28s 31ms/step - loss: 0.6491 - acc: 0.6076 - val_loss: 0.6323 - val_acc: 0.6535\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.65347, saving model to best_model_fold_0.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 13s 15ms/step - loss: 0.5507 - acc: 0.7336 - val_loss: 0.6304 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.65347 to 0.67327, saving model to best_model_fold_0.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 13s 14ms/step - loss: 0.4822 - acc: 0.7770 - val_loss: 0.5822 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.67327 to 0.69307, saving model to best_model_fold_0.hdf5\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.3639 - acc: 0.8239 - val_loss: 0.5832 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.69307\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.3382 - acc: 0.8484 - val_loss: 0.5613 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.69307 to 0.73267, saving model to best_model_fold_0.hdf5\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.3000 - acc: 0.8763 - val_loss: 0.5815 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73267 to 0.75248, saving model to best_model_fold_0.hdf5\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.1888 - acc: 0.9264 - val_loss: 0.7010 - val_acc: 0.7723\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.75248 to 0.77228, saving model to best_model_fold_0.hdf5\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.1424 - acc: 0.9487 - val_loss: 0.7858 - val_acc: 0.6634\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77228\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.1152 - acc: 0.9543 - val_loss: 0.8362 - val_acc: 0.7624\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.77228\n",
      "Epoch 10/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.0770 - acc: 0.9666 - val_loss: 1.2267 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.77228\n",
      "0.7722772277227723\n",
      "Fold 1 started at Wed Aug 28 08:59:08 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 27s 30ms/step - loss: 0.6802 - acc: 0.5753 - val_loss: 0.6118 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.68317, saving model to best_model_fold_1.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 13s 15ms/step - loss: 0.6012 - acc: 0.6957 - val_loss: 0.6652 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.68317 to 0.68317, saving model to best_model_fold_1.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 13s 14ms/step - loss: 0.5016 - acc: 0.7514 - val_loss: 0.6755 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.68317\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.4220 - acc: 0.8049 - val_loss: 0.9280 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.68317\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.4115 - acc: 0.8305 - val_loss: 0.6351 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.68317 to 0.73267, saving model to best_model_fold_1.hdf5\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.2820 - acc: 0.8863 - val_loss: 0.8562 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.73267\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.2785 - acc: 0.8907 - val_loss: 0.9013 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.73267\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.1925 - acc: 0.9287 - val_loss: 1.1024 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.73267\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.1189 - acc: 0.9599 - val_loss: 0.9523 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.73267 to 0.75248, saving model to best_model_fold_1.hdf5\n",
      "Epoch 10/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.1341 - acc: 0.9554 - val_loss: 1.1282 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.75248\n",
      "0.7524752475247525\n",
      "Fold 2 started at Wed Aug 28 09:07:31 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 29s 32ms/step - loss: 0.6762 - acc: 0.5808 - val_loss: 0.6084 - val_acc: 0.6535\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.65347, saving model to best_model_fold_2.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 14s 15ms/step - loss: 0.5638 - acc: 0.7146 - val_loss: 0.6189 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.65347 to 0.71287, saving model to best_model_fold_2.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 13s 14ms/step - loss: 0.4846 - acc: 0.7637 - val_loss: 0.5527 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.71287\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 13s 14ms/step - loss: 0.4117 - acc: 0.8105 - val_loss: 0.6756 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.71287\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.3537 - acc: 0.8350 - val_loss: 0.6453 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.71287 to 0.75248, saving model to best_model_fold_2.hdf5\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.2889 - acc: 0.8718 - val_loss: 0.8650 - val_acc: 0.6535\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75248\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.1803 - acc: 0.9231 - val_loss: 0.8924 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75248\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.1365 - acc: 0.9465 - val_loss: 1.3736 - val_acc: 0.6139\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75248\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 12s 14ms/step - loss: 0.0925 - acc: 0.9621 - val_loss: 1.0299 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.75248\n",
      "0.7524752475247525\n",
      "Fold 3 started at Wed Aug 28 09:15:44 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 28s 31ms/step - loss: 0.6875 - acc: 0.5791 - val_loss: 0.6307 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 14s 15ms/step - loss: 0.5556 - acc: 0.7294 - val_loss: 0.6256 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.70000\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 13s 15ms/step - loss: 0.5091 - acc: 0.7483 - val_loss: 0.5468 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.70000 to 0.73000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 13s 14ms/step - loss: 0.3907 - acc: 0.8330 - val_loss: 0.4802 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.73000 to 0.78000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 13s 14ms/step - loss: 0.3048 - acc: 0.8742 - val_loss: 0.5686 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.78000\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.2500 - acc: 0.8998 - val_loss: 0.5068 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.78000 to 0.80000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.1766 - acc: 0.9265 - val_loss: 0.6986 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.80000\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.1451 - acc: 0.9454 - val_loss: 0.8015 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80000\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.0696 - acc: 0.9699 - val_loss: 0.9335 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80000\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.0924 - acc: 0.9655 - val_loss: 0.8917 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.80000\n",
      "0.8\n",
      "Fold 4 started at Wed Aug 28 09:24:05 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 0.6654 - acc: 0.6225 - val_loss: 0.6322 - val_acc: 0.6300\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 13s 15ms/step - loss: 0.5815 - acc: 0.7016 - val_loss: 0.6413 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63000 to 0.70000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.5351 - acc: 0.7528 - val_loss: 0.4934 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.70000 to 0.78000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.4152 - acc: 0.8096 - val_loss: 0.4946 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.78000\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3776 - acc: 0.8296 - val_loss: 0.4914 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.78000\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.3102 - acc: 0.8630 - val_loss: 0.5023 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.78000 to 0.79000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.2006 - acc: 0.9109 - val_loss: 0.5551 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.79000 to 0.81000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.1441 - acc: 0.9421 - val_loss: 0.6881 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.81000\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.0830 - acc: 0.9666 - val_loss: 0.9455 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.81000\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 12s 14ms/step - loss: 0.0873 - acc: 0.9677 - val_loss: 0.9178 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81000\n",
      "0.81\n",
      "Fold 5 started at Wed Aug 28 09:32:26 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 30s 33ms/step - loss: 0.6658 - acc: 0.6062 - val_loss: 0.6788 - val_acc: 0.6162\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61616, saving model to best_model_fold_5.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.5522 - acc: 0.7442 - val_loss: 0.6437 - val_acc: 0.6364\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61616 to 0.63636, saving model to best_model_fold_5.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.4679 - acc: 0.8009 - val_loss: 0.6548 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.63636 to 0.67677, saving model to best_model_fold_5.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.3715 - acc: 0.8487 - val_loss: 0.5792 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.67677 to 0.70707, saving model to best_model_fold_5.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.3326 - acc: 0.8699 - val_loss: 0.8146 - val_acc: 0.6364\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.70707\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.2866 - acc: 0.8721 - val_loss: 0.7826 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.70707\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.1978 - acc: 0.9166 - val_loss: 1.0468 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.70707\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.1589 - acc: 0.9377 - val_loss: 0.7303 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.70707 to 0.72727, saving model to best_model_fold_5.hdf5\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.1015 - acc: 0.9655 - val_loss: 1.0292 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.72727 to 0.74747, saving model to best_model_fold_5.hdf5\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.1088 - acc: 0.9544 - val_loss: 0.9454 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.74747 to 0.74747, saving model to best_model_fold_5.hdf5\n",
      "0.7474747474747475\n",
      "Fold 6 started at Wed Aug 28 09:41:00 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 30s 33ms/step - loss: 0.6762 - acc: 0.5840 - val_loss: 0.6255 - val_acc: 0.6364\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63636, saving model to best_model_fold_6.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.5831 - acc: 0.6874 - val_loss: 0.6475 - val_acc: 0.5960\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.63636\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.4840 - acc: 0.7809 - val_loss: 0.6065 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.63636 to 0.72727, saving model to best_model_fold_6.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.4339 - acc: 0.8009 - val_loss: 0.6137 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.72727\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.3412 - acc: 0.8532 - val_loss: 0.6434 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72727 to 0.73737, saving model to best_model_fold_6.hdf5\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2697 - acc: 0.8843 - val_loss: 0.8253 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73737 to 0.76768, saving model to best_model_fold_6.hdf5\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2021 - acc: 0.9166 - val_loss: 0.8879 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.76768\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1916 - acc: 0.9266 - val_loss: 0.8879 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76768\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1083 - acc: 0.9611 - val_loss: 1.1033 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.76768\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.0723 - acc: 0.9722 - val_loss: 1.2885 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.76768\n",
      "0.7676767676767676\n",
      "Fold 7 started at Wed Aug 28 09:49:37 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 30s 34ms/step - loss: 0.6620 - acc: 0.5918 - val_loss: 0.6344 - val_acc: 0.6465\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64646, saving model to best_model_fold_7.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.5718 - acc: 0.7253 - val_loss: 0.5238 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.64646 to 0.71717, saving model to best_model_fold_7.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 13s 15ms/step - loss: 0.5112 - acc: 0.7597 - val_loss: 0.4880 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.71717 to 0.73737, saving model to best_model_fold_7.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 13s 15ms/step - loss: 0.4017 - acc: 0.8276 - val_loss: 0.4917 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.73737 to 0.75758, saving model to best_model_fold_7.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.3344 - acc: 0.8554 - val_loss: 0.5455 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75758\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2812 - acc: 0.8799 - val_loss: 0.6232 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75758\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1816 - acc: 0.9310 - val_loss: 0.7095 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75758\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.1548 - acc: 0.9388 - val_loss: 0.8084 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.75758\n",
      "0.7575757575757576\n",
      "Fold 8 started at Wed Aug 28 09:57:51 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 29s 33ms/step - loss: 0.6525 - acc: 0.6174 - val_loss: 0.5679 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.70707, saving model to best_model_fold_8.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 13s 15ms/step - loss: 0.5491 - acc: 0.7186 - val_loss: 0.5056 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.70707 to 0.73737, saving model to best_model_fold_8.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.4866 - acc: 0.7597 - val_loss: 0.6054 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.73737\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.4075 - acc: 0.8142 - val_loss: 0.5124 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.73737\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3324 - acc: 0.8509 - val_loss: 0.6400 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73737\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.2512 - acc: 0.8888 - val_loss: 0.6057 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73737 to 0.79798, saving model to best_model_fold_8.hdf5\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1633 - acc: 0.9399 - val_loss: 0.6655 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.79798\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1046 - acc: 0.9566 - val_loss: 1.0662 - val_acc: 0.7879\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.79798\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.1051 - acc: 0.9633 - val_loss: 0.9427 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.79798\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 12s 13ms/step - loss: 0.0722 - acc: 0.9722 - val_loss: 0.9833 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.79798\n",
      "0.797979797979798\n",
      "Fold 9 started at Wed Aug 28 10:06:20 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 31s 34ms/step - loss: 0.6560 - acc: 0.6307 - val_loss: 0.6020 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.74747, saving model to best_model_fold_9.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 13s 15ms/step - loss: 0.5243 - acc: 0.7486 - val_loss: 0.5760 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.74747\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 13s 14ms/step - loss: 0.4536 - acc: 0.7853 - val_loss: 0.5494 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.74747\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.3766 - acc: 0.8343 - val_loss: 0.6057 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.74747\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 12s 14ms/step - loss: 0.2791 - acc: 0.8799 - val_loss: 1.0510 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.74747\n",
      "0.7474747474747475\n",
      "b6_3_25    | 0.7631  0.7722  0.7618  0.7705  0.8283  0.6954 \n",
      "Fold 0 started at Wed Aug 28 10:13:53 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 34s 38ms/step - loss: 0.6509 - acc: 0.6065 - val_loss: 0.5906 - val_acc: 0.6040\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.60396, saving model to best_model_fold_0.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 16s 18ms/step - loss: 0.5575 - acc: 0.7291 - val_loss: 0.6086 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.60396 to 0.68317, saving model to best_model_fold_0.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 15s 16ms/step - loss: 0.4863 - acc: 0.7715 - val_loss: 0.5296 - val_acc: 0.7525\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.68317 to 0.75248, saving model to best_model_fold_0.hdf5\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.4625 - acc: 0.7960 - val_loss: 0.5297 - val_acc: 0.6832\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75248\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.4011 - acc: 0.8317 - val_loss: 0.5451 - val_acc: 0.7624\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.75248 to 0.76238, saving model to best_model_fold_0.hdf5\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.2774 - acc: 0.8952 - val_loss: 0.6330 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.76238\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.2150 - acc: 0.9086 - val_loss: 0.5506 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.76238\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.2617 - acc: 0.8841 - val_loss: 0.7501 - val_acc: 0.7228\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.76238\n",
      "Epoch 9/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.1263 - acc: 0.9487 - val_loss: 0.9417 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.76238\n",
      "0.7623762376237624\n",
      "Fold 1 started at Wed Aug 28 10:22:43 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 34s 38ms/step - loss: 0.6496 - acc: 0.6054 - val_loss: 1.5108 - val_acc: 0.5644\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.56436, saving model to best_model_fold_1.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 16s 18ms/step - loss: 0.5786 - acc: 0.7179 - val_loss: 0.6110 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.56436 to 0.67327, saving model to best_model_fold_1.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 15s 16ms/step - loss: 0.5305 - acc: 0.7614 - val_loss: 0.8010 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.67327\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.4706 - acc: 0.7860 - val_loss: 0.6409 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.67327 to 0.71287, saving model to best_model_fold_1.hdf5\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.4135 - acc: 0.8038 - val_loss: 0.7188 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.71287\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.3151 - acc: 0.8763 - val_loss: 0.6366 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.71287\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.2578 - acc: 0.8941 - val_loss: 0.6804 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.71287\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.1915 - acc: 0.9309 - val_loss: 1.1010 - val_acc: 0.6733\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.71287\n",
      "0.7128712871287128\n",
      "Fold 2 started at Wed Aug 28 10:31:16 2019\n",
      "Train on 897 samples, validate on 101 samples\n",
      "Epoch 1/10\n",
      "897/897 [==============================] - 36s 40ms/step - loss: 0.6721 - acc: 0.5975 - val_loss: 0.6918 - val_acc: 0.5941\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59406, saving model to best_model_fold_2.hdf5\n",
      "Epoch 2/10\n",
      "897/897 [==============================] - 16s 17ms/step - loss: 0.5606 - acc: 0.7213 - val_loss: 0.5792 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59406 to 0.71287, saving model to best_model_fold_2.hdf5\n",
      "Epoch 3/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.4616 - acc: 0.7860 - val_loss: 0.6453 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.71287\n",
      "Epoch 4/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.4192 - acc: 0.8161 - val_loss: 0.5583 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.71287 to 0.74257, saving model to best_model_fold_2.hdf5\n",
      "Epoch 5/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.3409 - acc: 0.8528 - val_loss: 0.5820 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.74257\n",
      "Epoch 6/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.2181 - acc: 0.9108 - val_loss: 0.7786 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.74257\n",
      "Epoch 7/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.1992 - acc: 0.9253 - val_loss: 0.8170 - val_acc: 0.7327\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.74257\n",
      "Epoch 8/10\n",
      "897/897 [==============================] - 14s 16ms/step - loss: 0.1446 - acc: 0.9431 - val_loss: 1.0167 - val_acc: 0.6337\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74257\n",
      "0.7425742574257426\n",
      "Fold 3 started at Wed Aug 28 10:40:05 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 36s 40ms/step - loss: 0.6501 - acc: 0.6192 - val_loss: 0.6141 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 0.5603 - acc: 0.7127 - val_loss: 0.5744 - val_acc: 0.6800\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.71000\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 0.4589 - acc: 0.7940 - val_loss: 0.5111 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.71000\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 0.4243 - acc: 0.7984 - val_loss: 0.5214 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.71000 to 0.72000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 14s 15ms/step - loss: 0.3623 - acc: 0.8374 - val_loss: 0.6060 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72000 to 0.74000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 14s 15ms/step - loss: 0.2821 - acc: 0.8775 - val_loss: 0.5165 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.74000\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 14s 15ms/step - loss: 0.2042 - acc: 0.9143 - val_loss: 0.9303 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.74000\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 14s 15ms/step - loss: 0.1622 - acc: 0.9287 - val_loss: 0.8565 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.74000 to 0.76000, saving model to best_model_fold_3.hdf5\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 13s 15ms/step - loss: 0.0909 - acc: 0.9655 - val_loss: 1.5181 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.76000\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 13s 15ms/step - loss: 0.1165 - acc: 0.9599 - val_loss: 0.8337 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.76000\n",
      "0.76\n",
      "Fold 4 started at Wed Aug 28 10:49:23 2019\n",
      "Train on 898 samples, validate on 100 samples\n",
      "Epoch 1/10\n",
      "898/898 [==============================] - 37s 42ms/step - loss: 0.6744 - acc: 0.6002 - val_loss: 0.6679 - val_acc: 0.6100\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 16s 18ms/step - loss: 0.5821 - acc: 0.7004 - val_loss: 0.5504 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61000 to 0.73000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 15s 17ms/step - loss: 0.4799 - acc: 0.7728 - val_loss: 0.5860 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.73000\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 0.4161 - acc: 0.8252 - val_loss: 0.6928 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.73000 to 0.75000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 0.3452 - acc: 0.8608 - val_loss: 0.5156 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.75000 to 0.77000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 0.2512 - acc: 0.8998 - val_loss: 0.5407 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77000\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 0.1945 - acc: 0.9298 - val_loss: 0.5727 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.77000 to 0.80000, saving model to best_model_fold_4.hdf5\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 14s 16ms/step - loss: 0.1279 - acc: 0.9488 - val_loss: 0.8247 - val_acc: 0.6500\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.80000\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 14s 15ms/step - loss: 0.1315 - acc: 0.9488 - val_loss: 0.5924 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.80000\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 14s 15ms/step - loss: 0.0687 - acc: 0.9722 - val_loss: 1.1134 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.80000\n",
      "0.8\n",
      "Fold 5 started at Wed Aug 28 10:58:45 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 37s 41ms/step - loss: 0.6806 - acc: 0.5762 - val_loss: 0.6395 - val_acc: 0.6162\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61616, saving model to best_model_fold_5.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 15s 17ms/step - loss: 0.5687 - acc: 0.7130 - val_loss: 0.5857 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61616 to 0.69697, saving model to best_model_fold_5.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.4813 - acc: 0.7842 - val_loss: 0.5597 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.69697 to 0.70707, saving model to best_model_fold_5.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.4105 - acc: 0.8265 - val_loss: 0.6071 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.70707\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3210 - acc: 0.8676 - val_loss: 0.7129 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.70707 to 0.72727, saving model to best_model_fold_5.hdf5\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2668 - acc: 0.8854 - val_loss: 0.6908 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72727\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1987 - acc: 0.9177 - val_loss: 0.7896 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.72727\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1421 - acc: 0.9422 - val_loss: 0.8605 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.72727\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 13s 15ms/step - loss: 0.1112 - acc: 0.9600 - val_loss: 0.8091 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.72727\n",
      "0.7272727272727273\n",
      "Fold 6 started at Wed Aug 28 11:07:52 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 38s 43ms/step - loss: 0.6715 - acc: 0.5873 - val_loss: 0.5856 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69697, saving model to best_model_fold_6.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 16s 17ms/step - loss: 0.5686 - acc: 0.7130 - val_loss: 0.5837 - val_acc: 0.7374\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69697 to 0.73737, saving model to best_model_fold_6.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.4677 - acc: 0.7853 - val_loss: 0.6101 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73737 to 0.75758, saving model to best_model_fold_6.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.3858 - acc: 0.8376 - val_loss: 0.7175 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.75758\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.3187 - acc: 0.8643 - val_loss: 0.8557 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.75758\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2797 - acc: 0.8776 - val_loss: 1.0142 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.75758\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1923 - acc: 0.9132 - val_loss: 1.1995 - val_acc: 0.6162\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.75758\n",
      "0.7575757575757576\n",
      "Fold 7 started at Wed Aug 28 11:16:41 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 36s 40ms/step - loss: 0.6682 - acc: 0.6129 - val_loss: 0.5809 - val_acc: 0.6465\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.64646, saving model to best_model_fold_7.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 16s 17ms/step - loss: 0.5789 - acc: 0.7052 - val_loss: 0.5859 - val_acc: 0.6465\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.64646\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 15s 16ms/step - loss: 0.5304 - acc: 0.7542 - val_loss: 0.4588 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.64646 to 0.79798, saving model to best_model_fold_7.hdf5\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.4219 - acc: 0.8042 - val_loss: 0.4414 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.79798\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.3463 - acc: 0.8576 - val_loss: 0.5993 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.79798\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.2434 - acc: 0.9010 - val_loss: 0.6071 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.79798\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.2323 - acc: 0.9099 - val_loss: 0.5033 - val_acc: 0.8182\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.79798 to 0.81818, saving model to best_model_fold_7.hdf5\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1557 - acc: 0.9422 - val_loss: 0.6365 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.81818\n",
      "Epoch 9/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.1324 - acc: 0.9600 - val_loss: 0.6168 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.81818\n",
      "Epoch 10/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.0947 - acc: 0.9733 - val_loss: 0.7340 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.81818\n",
      "0.8181818181818182\n",
      "Fold 8 started at Wed Aug 28 11:25:47 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 37s 41ms/step - loss: 0.6732 - acc: 0.5795 - val_loss: 0.5741 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.69697, saving model to best_model_fold_8.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 16s 17ms/step - loss: 0.5608 - acc: 0.7175 - val_loss: 0.4862 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.69697 to 0.75758, saving model to best_model_fold_8.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 15s 16ms/step - loss: 0.4748 - acc: 0.7798 - val_loss: 0.5274 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.75758\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.3816 - acc: 0.8276 - val_loss: 0.5157 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.75758 to 0.77778, saving model to best_model_fold_8.hdf5\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.2839 - acc: 0.8799 - val_loss: 0.5219 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77778\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.1944 - acc: 0.9110 - val_loss: 0.6338 - val_acc: 0.7677\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77778\n",
      "Epoch 7/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.1578 - acc: 0.9399 - val_loss: 0.7728 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.77778\n",
      "Epoch 8/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.1287 - acc: 0.9533 - val_loss: 0.7650 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.77778\n",
      "0.7777777777777778\n",
      "Fold 9 started at Wed Aug 28 11:34:36 2019\n",
      "Train on 899 samples, validate on 99 samples\n",
      "Epoch 1/10\n",
      "899/899 [==============================] - 39s 43ms/step - loss: 0.6623 - acc: 0.6029 - val_loss: 0.5447 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71717, saving model to best_model_fold_9.hdf5\n",
      "Epoch 2/10\n",
      "899/899 [==============================] - 15s 17ms/step - loss: 0.5352 - acc: 0.7375 - val_loss: 0.4985 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71717 to 0.77778, saving model to best_model_fold_9.hdf5\n",
      "Epoch 3/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.4817 - acc: 0.7664 - val_loss: 0.5568 - val_acc: 0.7475\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.77778\n",
      "Epoch 4/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.3848 - acc: 0.8254 - val_loss: 0.5452 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.77778\n",
      "Epoch 5/10\n",
      "899/899 [==============================] - 14s 16ms/step - loss: 0.2986 - acc: 0.8743 - val_loss: 0.6286 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.77778\n",
      "Epoch 6/10\n",
      "899/899 [==============================] - 14s 15ms/step - loss: 0.2001 - acc: 0.9188 - val_loss: 0.6116 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.77778\n",
      "0.7777777777777778\n",
      "b6_3_30    | 0.7578  0.7632  0.7587  0.7636  0.7963  0.7210 \n"
     ]
    }
   ],
   "source": [
    "for emb_ma in [1,2,3]:\n",
    "    embed_size = 150 # * 2 = 300 for matrix 1 and 2\n",
    "    if emb_ma == 3:\n",
    "        embed_size = 300\n",
    "    for max_len in [100,150,200,250,300]: \n",
    "        run_model_on_fold('b1_'+str(emb_ma)+'_'+str(max_len),max_len,embed_size,emb_ma,build_model1)\n",
    "        run_model_on_fold('b2_'+str(emb_ma)+'_'+str(max_len),max_len,embed_size,emb_ma,build_model2)\n",
    "        run_model_on_fold('b3_'+str(emb_ma)+'_'+str(max_len),max_len,embed_size,emb_ma,build_model3)\n",
    "        run_model_on_fold('b4_'+str(emb_ma)+'_'+str(max_len),max_len,embed_size,emb_ma,build_model4)\n",
    "        run_model_on_fold('b5_'+str(emb_ma)+'_'+str(max_len),max_len,embed_size,emb_ma,build_model5)\n",
    "        run_model_on_fold('b6_'+str(emb_ma)+'_'+str(max_len),max_len,embed_size,emb_ma,build_model6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RHhhcN2BAKEw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CNN+Class.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
